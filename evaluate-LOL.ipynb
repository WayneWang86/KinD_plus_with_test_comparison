{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13deaf7c-5c03-43e2-969d-0e46e078a084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ./checkpoint/decom_model/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/decom_model/model.ckpt\n",
      "loaded ./checkpoint/illu_model/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/illu_model/model.ckpt\n",
      "loaded ./checkpoint/restoration_model/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/restoration_model/model.ckpt\n",
      "(400, 600, 3)\n",
      "(400, 600, 3)\n",
      "(400, 600, 3)\n",
      "(400, 600, 3)\n",
      "(400, 600, 3)\n",
      "(400, 600, 3)\n",
      "(400, 600, 3)\n",
      "(400, 600, 3)\n",
      "(400, 600, 3)\n",
      "(400, 600, 3)\n",
      "(400, 600, 3)\n",
      "(400, 600, 3)\n",
      "(400, 600, 3)\n",
      "(400, 600, 3)\n",
      "(400, 600, 3)\n",
      "Start evalating!\n",
      "0\n",
      "Evaluate image 1\n",
      "1\n",
      "Evaluate image 111\n",
      "2\n",
      "Evaluate image 146\n",
      "3\n",
      "Evaluate image 179\n",
      "4\n",
      "Evaluate image 22\n",
      "5\n",
      "Evaluate image 23\n",
      "6\n",
      "Evaluate image 493\n",
      "7\n",
      "Evaluate image 547\n",
      "8\n",
      "Evaluate image 55\n",
      "9\n",
      "Evaluate image 665\n",
      "10\n",
      "Evaluate image 669\n",
      "11\n",
      "Evaluate image 748\n",
      "12\n",
      "Evaluate image 778\n",
      "13\n",
      "Evaluate image 780\n",
      "14\n",
      "Evaluate image 79\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from model import *\n",
    "from glob import glob\n",
    "import argparse\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "parser = argparse.ArgumentParser(description='')\n",
    "\n",
    "# parser.add_argument('--save_dir', dest='save_dir', default='./test_results/sys_low', help='directory for testing outputs')\n",
    "# parser.add_argument('--test_dir', dest='test_dir', default='./LOLdataset/sys_low/', help='directory for testing inputs')\n",
    "\n",
    "parser.add_argument('--save_dir', dest='save_dir', default='./test_results/eval15', help='directory for testing outputs')\n",
    "parser.add_argument('--test_dir', dest='test_dir', default='./LOLdataset/eval15/', help='directory for testing inputs')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "\n",
    "sess = tf.compat.v1.Session()\n",
    "training = tf.compat.v1.placeholder_with_default(False, shape=(), name='training')\n",
    "input_decom = tf.compat.v1.placeholder(tf.compat.v1.float32, [None, None, None, 3], name='input_decom')\n",
    "input_low_r = tf.compat.v1.placeholder(tf.compat.v1.float32, [None, None, None, 3], name='input_low_r')\n",
    "input_low_i = tf.compat.v1.placeholder(tf.compat.v1.float32, [None, None, None, 1], name='input_low_i')\n",
    "input_low_i_ratio = tf.compat.v1.placeholder(tf.compat.v1.float32, [None, None, None, 1], name='input_low_i_ratio')\n",
    "\n",
    "[R_decom, I_decom] = DecomNet(input_decom)\n",
    "decom_output_R = R_decom\n",
    "decom_output_I = I_decom\n",
    "output_r = Restoration_net(input_low_r, input_low_i, training)\n",
    "output_i = Illumination_adjust_net(input_low_i, input_low_i_ratio)\n",
    "\n",
    "# load pretrained model parameters\n",
    "var_Decom = [var for var in tf.compat.v1.trainable_variables() if 'DecomNet' in var.name]\n",
    "var_adjust = [var for var in tf.compat.v1.trainable_variables() if 'I_enhance_Net' in var.name]\n",
    "var_restoration = [var for var in tf.compat.v1.trainable_variables() if 'Denoise_Net' in var.name]\n",
    "g_list = tf.compat.v1.global_variables()\n",
    "bn_moving_vars = [g for g in g_list if 'moving_mean' in g.name]\n",
    "bn_moving_vars += [g for g in g_list if 'moving_variance' in g.name]\n",
    "var_restoration += bn_moving_vars\n",
    "\n",
    "saver_Decom = tf.compat.v1.train.Saver(var_list = var_Decom)\n",
    "saver_adjust = tf.compat.v1.train.Saver(var_list=var_adjust)\n",
    "saver_restoration = tf.compat.v1.train.Saver(var_list=var_restoration)\n",
    "\n",
    "decom_checkpoint_dir ='./checkpoint/decom_model/'\n",
    "ckpt_pre=tf.compat.v1.train.get_checkpoint_state(decom_checkpoint_dir)\n",
    "if ckpt_pre:\n",
    "    print('loaded '+ckpt_pre.model_checkpoint_path)\n",
    "    saver_Decom.restore(sess,ckpt_pre.model_checkpoint_path)\n",
    "else:\n",
    "    print('No decomnet pretrained model!')\n",
    "\n",
    "checkpoint_dir_adjust = './checkpoint/illu_model/'\n",
    "ckpt_adjust=tf.compat.v1.train.get_checkpoint_state(checkpoint_dir_adjust)\n",
    "if ckpt_adjust:\n",
    "    print('loaded '+ckpt_adjust.model_checkpoint_path)\n",
    "    saver_adjust.restore(sess,ckpt_adjust.model_checkpoint_path)\n",
    "else:\n",
    "    print(\"No adjust net pretrained model!\")\n",
    "\n",
    "checkpoint_dir_restoration = './checkpoint/restoration_model/'\n",
    "ckpt=tf.compat.v1.train.get_checkpoint_state(checkpoint_dir_restoration)\n",
    "if ckpt:\n",
    "    print('loaded '+ckpt.model_checkpoint_path)\n",
    "    saver_restoration.restore(sess,ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    print(\"No restoration net pretrained model!\")\n",
    "\n",
    "###load eval data\n",
    "eval_low_data = []\n",
    "eval_img_name =[]\n",
    "eval_low_data_name = glob(args.test_dir + '/low/*.png')\n",
    "eval_low_data_name.sort()\n",
    "for idx in range(len(eval_low_data_name)):\n",
    "    [_, name] = os.path.split(eval_low_data_name[idx])\n",
    "    suffix = name[name.find('.') + 1:]\n",
    "    name = name[:name.find('.')]\n",
    "    eval_img_name.append(name)\n",
    "    eval_low_im = load_images(eval_low_data_name[idx])\n",
    "    eval_low_data.append(eval_low_im)\n",
    "    print(eval_low_im.shape)\n",
    "# To get better results, the illumination adjustment ratio is computed based on the decom_i_high, so we also need the high data.\n",
    "eval_high_data = []\n",
    "eval_high_data_name = glob(args.test_dir + '/high/*.png')\n",
    "eval_high_data_name.sort()\n",
    "for idx in range(len(eval_high_data_name)):\n",
    "    eval_high_im = load_images(eval_high_data_name[idx])\n",
    "    eval_high_data.append(eval_high_im)\n",
    "\n",
    "sample_dir = args.save_dir +'/LOLdataset/'\n",
    "if not os.path.isdir(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "print(\"Start evalating!\")\n",
    "start_time = time.time()\n",
    "for idx in range(len(eval_low_data)):\n",
    "    print(idx)\n",
    "    name = eval_img_name[idx]\n",
    "    print('Evaluate image %s'%name)\n",
    "    input_low = eval_low_data[idx]\n",
    "    input_low_eval = np.expand_dims(input_low, axis=0)\n",
    "    input_high = eval_high_data[idx]\n",
    "    input_high_eval = np.expand_dims(input_high, axis=0)\n",
    "    h, w, _ = input_low.shape\n",
    "\n",
    "    decom_r_low, decom_i_low = sess.run([decom_output_R, decom_output_I], feed_dict={input_decom: input_low_eval})\n",
    "    decom_r_high, decom_i_high = sess.run([decom_output_R, decom_output_I], feed_dict={input_decom: input_high_eval})\n",
    "    \n",
    "    restoration_r = sess.run(output_r, feed_dict={input_low_r: decom_r_low, input_low_i: decom_i_low})\n",
    "\n",
    "    ratio = np.mean(((decom_i_high))/(decom_i_low+0.0001))\n",
    "    ratio2 = np.mean(((decom_r_high))/(restoration_r+0.0001))\n",
    "    if ratio2<1.1:\n",
    "        i_low_data_ratio = np.ones([h, w])*(ratio)\n",
    "    else:\n",
    "        i_low_data_ratio = np.ones([h, w])*(ratio+ratio2)\n",
    "    \n",
    "    i_low_ratio_expand = np.expand_dims(i_low_data_ratio , axis =2)\n",
    "    i_low_ratio_expand2 = np.expand_dims(i_low_ratio_expand, axis=0)\n",
    "\n",
    "    adjust_i = sess.run(output_i, feed_dict={input_low_i: decom_i_low, input_low_i_ratio: i_low_ratio_expand2})\n",
    "    fusion = restoration_r*adjust_i\n",
    "    \n",
    "    save_images(os.path.join(sample_dir, '%s_kindle_v2.png' % (name)), fusion)\n",
    "    #save_images(os.path.join(sample_dir, '%s_decom_i_low.png' % (name)), decom_i_low)\n",
    "    #save_images(os.path.join(sample_dir, '%s_adjust_i_%f.png' % (name, (ratio+ratio2)) ), adjust_i)\n",
    "    #save_images(os.path.join(sample_dir, '%s_denoise_r.png' % (name)), restoration_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1a2a3-ddae-4e52-b181-6e71df0df42d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6be851-5187-4c68-8741-43ee614630ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
